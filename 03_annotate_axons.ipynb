{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate the growth cones in the timelapse. Load the signal channel and background, save an rgb .npy array for visualizing later. Main purpose here is however to label growth cones. Create some empty shapes layers in napari, then label manually. After that, run the SAVE axon labels cells. One can also read in already labelled axons using the LOAD cell. This also checks if a sequence of detections is continueos (no timepoints skipped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from tifffile import imread\n",
    "%gui qt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_path = '/run/media/loaloa/lbb_ssd/timelapse01_40_min_processed/'\n",
    "inp_path = '/run/media/loaloa/lbb_ssd/timelapse13_processed_nexw/'\n",
    "\n",
    "# inp_path = '/home/loaloa/Documents/'\n",
    "# outp_path = '../tl140_outputdata'\n",
    "\n",
    "red_file = inp_path+'D01 _G001_GFP_compr.deflate.tif'\n",
    "redchannel = imread(red_file)\n",
    "sizet, sizey, sizex = redchannel.shape\n",
    "ymin, ymax = 0, sizey\n",
    "xmin, xmax = 0, sizex\n",
    "\n",
    "tranl_file = inp_path+'D01 _G001_Transmission_compr.deflate.tif'\n",
    "greychannel = imread(tranl_file)[0]\n",
    "\n",
    "# viewer.add_points(name='outputchannel')\n",
    "target = (991, 2746)\n",
    "sizet = redchannel.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask image to relevant area\n",
    "excl_mask = np.load(f'{outp_path}/mask_wells_excl.npy')\n",
    "mask = np.load(f'{outp_path}/mask_wells_incl.npy')\n",
    "# greychannel[~mask.astype(bool)] = 0\n",
    "redchannel[:,~mask.astype(bool)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create merged image (for showcasing results later)\n",
    "grey = greychannel*3\n",
    "rgb_image = np.stack([grey]*3, -1)\n",
    "rgb_image = np.stack([rgb_image]*redchannel.shape[0], 0)\n",
    "\n",
    "r = redchannel*13\n",
    "rgb_image[:,:,:,0] += r\n",
    "\n",
    "np.save(f'{outp_path}/rgb_seq_vanilla.npy', rgb_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loaloa/programs/anaconda3/lib/python3.8/site-packages/napari/_qt/qt_event_loop.py:256: FutureWarning: \n",
      "The 'gui_qt()' context manager is deprecated.\n",
      "If you are running napari from a script, please use 'napari.run()' as follows:\n",
      "\n",
      "    import napari\n",
      "\n",
      "    viewer = napari.Viewer()  # no prior setup needed\n",
      "    # other code using the viewer...\n",
      "    napari.run()\n",
      "\n",
      "In IPython or Jupyter, 'napari.run()' is not necessary. napari will automatically\n",
      "start an interactive event loop for you: \n",
      "\n",
      "    import napari\n",
      "    viewer = napari.Viewer()  # that's it!\n",
      "\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymin, ymax = 1300, 2500\n",
    "xmin, xmax = 0, 2000\n",
    "redchannel = redchannel[:, ymin:ymax,xmin:xmax]\n",
    "sizey, sizex = redchannel.shape[1:]\n",
    "# greychannel = greychannel[1300:,:2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "No such file: '/home/loaloa/gdrive/projects/PDMS frame files/wafer_version2/design_masks/timelapse_designs_mask_D1.png'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-de6159907b7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./../../PDMS frame files/wafer_version2/design_masks/timelapse_designs_mask_D1.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/napari-env/lib/python3.8/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/napari-env/lib/python3.8/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Create request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# Get format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/napari-env/lib/python3.8/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Parse what was given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Set extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/anaconda3/envs/napari-env/lib/python3.8/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/home/loaloa/gdrive/projects/PDMS frame files/wafer_version2/design_masks/timelapse_designs_mask_D1.png'"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "im = imageio.imread('./../PDMS frame files/wafer_version2/design_masks/timelapse_designs_mask_D1.png')\n",
    "viewer.add_image(im)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(redchannel)\n",
    "viewer.layers['redchannel'].blending = 'additive'\n",
    "viewer.layers['redchannel'].colormap = 'red'\n",
    "viewer.layers['redchannel'].contrast_limits = [0,2700]\n",
    "\n",
    "viewer.add_image(greychannel)\n",
    "viewer.layers['greychannel'].blending='additive'\n",
    "viewer.layers['greychannel'].opacity = .1\n",
    "viewer.layers['greychannel'].gamma = .6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute motion and add to viewer\n",
    "blur_strength = 3\n",
    "lowerlim = 100\n",
    "print(f'Calculating motion (clip lower lim: {lowerlim}) + '\n",
    "      f'Gaussian filtering (std: {blur_strength})...', end='')\n",
    "\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "pos_motion_seq = [np.zeros((sizey, sizex), float)]\n",
    "neg_motion_seq = [np.zeros((sizey, sizex), float)]\n",
    "# first timepoint has no t-1, set to all 0. Recommend to not use t=0\n",
    "print()\n",
    "for t in range(1, sizet):\n",
    "    motion_frame = redchannel[t].astype(float) - redchannel[t-1].astype(float)\n",
    "    motion_frame = gaussian(motion_frame.astype(float), blur_strength)\n",
    "        \n",
    "    # clipping\n",
    "    motion_frame[np.abs(motion_frame)<lowerlim] = 0\n",
    "\n",
    "    pos_motion = np.where(motion_frame>0, motion_frame, 0).astype(np.uint16)\n",
    "    neg_motion = np.where(motion_frame<0, motion_frame*-1, 0).astype(np.uint16)\n",
    "    \n",
    "    pos_motion_seq.append(pos_motion)\n",
    "    neg_motion_seq.append(neg_motion)\n",
    "    \n",
    "print('Done.')\n",
    "\n",
    "pos_motion_seq = np.stack(pos_motion_seq).astype(np.uint16)\n",
    "neg_motion_seq = np.stack(neg_motion_seq).astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(pos_motion_seq)\n",
    "viewer.layers['pos_motion_seq'].blending = 'additive'\n",
    "viewer.layers['pos_motion_seq'].colormap = 'green'\n",
    "viewer.layers['pos_motion_seq'].contrast_limits = [0,2700]\n",
    "\n",
    "viewer.add_image(neg_motion_seq)\n",
    "viewer.layers['neg_motion_seq'].blending = 'additive'\n",
    "viewer.layers['neg_motion_seq'].colormap = 'blue'\n",
    "viewer.layers['neg_motion_seq'].contrast_limits = [0,2700]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE EMPTY AXON LABELS\n",
    "axons_index = range(78,100)\n",
    "\n",
    "for ax_i in axons_index:\n",
    "    name = f'Axon_{ax_i:0>3}'\n",
    "    col = np.random.rand(1,3)\n",
    "    # edge coloring doesn't work unfortunately, do manually in gui\n",
    "    viewer.add_shapes(name=name, shape_type='rectangle', edge_color=col, face_color=np.array([1,1,1,.2]), opacity=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE NEW AXON LABEL LAYERS\n",
    "mk_axons_index = range(75,76)\n",
    "for i in mk_axons_index:\n",
    "    name = f'axon_{i}'\n",
    "    col = np.random.rand(1,3)\n",
    "    init_data =  np.array([[0,0,0],\n",
    "                           [0,0,0],\n",
    "                           [0,0,0],\n",
    "                           [0,0,0]])\n",
    "    viewer.add_shapes(name=name, shape_type='rectangle', edge_color=col, face_color=np.array([1,1,1,.15]), edge_width=3)\n",
    "    viewer.layers[name].data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SAVE AXONS\n",
    "print('SAVING...')\n",
    "axons_index = range(100)\n",
    "\n",
    "# backup for safety always created new\n",
    "dir_name = f'{outp_path}/labelled_axons_backup/labelled_axons n{len(axons_index)}.{time.ctime(time.time())}'\n",
    "os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "all_axons_df = []\n",
    "for ax_i in axons_index:\n",
    "    name = f'Axon_{ax_i:0>3}'\n",
    "    # old labelling, save base object as .npy, Used for loading axon bboxes in this script\n",
    "    labels = np.array(viewer.layers[name].data)\n",
    "    np.save(f'{dir_name}/{name}.npy', labels)   # safety backup\n",
    "    np.save(f'{outp_path}/labelled_axons/{name}.npy', labels)   # what's actually used\n",
    "\n",
    "    # make dataframe to save all information\n",
    "    timepoints = labels[:,0,0].astype(int)\n",
    "    print(f'{name} n={viewer.layers[name].nshapes}...', end='')\n",
    "    # create a pandas dataframe for this specific axons\n",
    "    idx = pd.MultiIndex.from_product([(name,),\n",
    "                                    ('anchor_x', 'anchor_y', 'extend', \n",
    "                                     'topleft_x', 'topleft_y', \n",
    "                                     'bottomright_x', 'bottomright_y', \n",
    "                                     'distance', 'rel_distance',\n",
    "                                     'col_r', 'col_g', 'col_b',)])\n",
    "    dat = pd.DataFrame(index=range(sizet), columns=idx)\n",
    "    \n",
    "    # populate the dataframe with all the relvent bbox information\n",
    "    color = viewer.layers[name].edge_color\n",
    "    dat.loc[timepoints, (name, ['col_r', 'col_g', 'col_b'])] = color[:,:-1]\n",
    "        \n",
    "    start = labels[:, :,1:].min(axis=1).astype(int)\n",
    "    end = labels[:,:,1:].max(axis=1).astype(int)\n",
    "    dat.loc[timepoints, (name, 'topleft_x')] = start[:, 1]\n",
    "    dat.loc[timepoints, (name, 'topleft_y')] = start[:, 0]\n",
    "    dat.loc[timepoints, (name, 'bottomright_x')] = end[:, 1]\n",
    "    dat.loc[timepoints, (name, 'bottomright_y')] = end[:, 0]\n",
    "\n",
    "    x_dist, y_dist = end[:,1]-start[:,1], end[:,0]-start[:,0]\n",
    "    extend = ((x_dist+y_dist)//4).astype(int)\n",
    "    dat.loc[timepoints, (name, 'extend')] = extend\n",
    "\n",
    "    anchor_x = (start[:,1] + extend).astype(int)\n",
    "    anchor_y = (start[:,0] + extend).astype(int)\n",
    "    dat.loc[timepoints, (name, 'anchor_x')] = anchor_x\n",
    "    dat.loc[timepoints, (name, 'anchor_y')] = anchor_y\n",
    "    # this is the old way of computing distance: simply eucl. \n",
    "    dist = np.sqrt((anchor_x-target[1])**2 + (anchor_y-target[0])**2)\n",
    "    dat.loc[timepoints, (name, 'distance')] = dist\n",
    "    dat.loc[timepoints, (name, 'rel_distance')] = dist[np.where(timepoints == min(timepoints))] - dist\n",
    "\n",
    "    all_axons_df.append(dat)\n",
    "    print('Ok.')\n",
    "all_axons_df = pd.concat(all_axons_df, axis=1).sort_index(axis=1)\n",
    "all_axons_df.to_csv(f'{outp_path}/labelled_axons_eucldists_new.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import gray2rgb\n",
    "from skimage import img_as_float\n",
    "from skimage.draw import rectangle_perimeter\n",
    "from skimage import img_as_uint\n",
    "\n",
    "redchannel_float = img_as_float(redchannel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_image = np.zeros((sizet, sizey, sizex, 3), float)\n",
    "rgb_image[:,:,:,0] = redchannel_float\n",
    "rgb_image /= rgb_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AXONS AS LAYERS, or rgb image, show which timepoint is lablled \n",
    "as_shapes = True\n",
    "print('LOADING axon bboxes....')\n",
    "load_axons_range = range(100)\n",
    "\n",
    "labelled = np.zeros((load_axons_range[-1]+1,sizet))\n",
    "for i in load_axons_range:\n",
    "    name = f'Axon_{i:0>3}'\n",
    "    print(f'{name}...', end='')\n",
    "    col = np.random.rand(1,3)\n",
    "    dat = np.load(f'{outp_path}/labelled_axons/{name}.npy', )\n",
    "    labelled[i,:] = [1 if t in dat[:,:,0].flatten() else 0 for t in range(sizet)]   # for plotting\n",
    "    # dat[:,:,1] -= ymin\n",
    "    # dat[:,:,2] -= xmin\n",
    "    \n",
    "    if not dat.size:\n",
    "        print('!!!Empty!!!\\n')\n",
    "        continue\n",
    "    dupl_label = any([(dat[:,:,0]==t).sum()>4 for t in range(sizet)])\n",
    "    if dupl_label:\n",
    "        [print(f't: {t} - More than one label!') for t in range(sizet) if (dat[:,:,0]==t).sum()>4]        \n",
    "        print()\n",
    "    else:\n",
    "        print('Ok')\n",
    "    if as_shapes:\n",
    "        viewer.add_shapes(dat, name=name, shape_type='rectangle', edge_color=col, face_color=np.array([1,1,1,.9]), edge_width=5, visible=True, opacity=.9)\n",
    "    else:\n",
    "        start = dat[:, :,1:].min(axis=1).astype(int)\n",
    "        end = dat[:,:,1:].max(axis=1).astype(int)\n",
    "        x_start = start[:, 1]\n",
    "        y_start = start[:, 0]\n",
    "        x_end = end[:, 1]\n",
    "        y_end = end[:, 0]\n",
    "        \n",
    "#         col = 1 - .35*(1-col) \n",
    "        axon_timepoints = dat[:,:,0].astype(int)\n",
    "        for i, t in enumerate(range(axon_timepoints.min(), axon_timepoints.max()+1)):\n",
    "            for w in range(2):\n",
    "                rr, cc = rectangle_perimeter((y_start[i]+w, x_start[i]+w), end=(y_end[i]+w, x_end[i]+w), \n",
    "                                             shape=rgb_image.shape[1:])\n",
    "                rgb_image[t-1, rr, cc] = col\n",
    "\n",
    "plt.figure(figsize=(13,7), facecolor='k')\n",
    "plt.imshow(labelled.T, cmap=plt.get_cmap('cividis'))\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_yticks(np.arange(sizet))\n",
    "ax.set_yticklabels(['' if t%5 else t for t in range(sizet)], color='white')\n",
    "ax.set_ylabel('timepoint', color='white', fontsize=14)\n",
    "\n",
    "ax.set_xticks(np.arange(load_axons_range[-1]+1))\n",
    "ax.set_xticklabels(['' if t%2 else t for t in range(load_axons_range[-1]+1)], color='white')\n",
    "ax.set_xlabel('Axon ID', color='white', fontsize=14)\n",
    "\n",
    "ax.set_title('Yellow means there is an axon label for this timepoint', color='white', fontsize=18)\n",
    "ax.set_yticks(np.arange(sizet))\n",
    "ax.set_yticklabels(['' if t%4 else t+1 for t in range(sizet)], color='white')\n",
    "ax.set_ylabel('timepoint', color='white', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(rgb_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}